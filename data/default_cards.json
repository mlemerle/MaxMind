{
  "cards": [
    {"front":"Expected value (EV)?","back":"Sum of outcomes weighted by probabilities; choose the higher EV if risk-neutral.","tags":["decision"]},
    {"front":"Base rate - why it matters","back":"It's the prior prevalence; ignoring it leads to base-rate neglect and miscalibration.","tags":["probability"]},
    {"front":"Backdoor path (DAG)","back":"Non-causal path X to Y; block with the right covariates.","tags":["causal"]},
    {"front":"Sunk cost fallacy antidote","back":"Ignore irrecoverable costs; evaluate the future only.","tags":["debias"]},
    {"front":"Fermi first step","back":"Define target precisely; decompose; use reference classes.","tags":["estimation"]},
    {"front":"Well-calibrated forecast","back":"Of events you call 70%, approximately 70% happen in the long run.","tags":["forecasting"]},
    {"front":"Moloch","back":"Metaphor for any system-level dynamic that sacrifices individual values for collective failure.","tags":["rationalism","systems"]},
    {"front":"Malthusian Trap","back":"When population growth outpaces productivity, wealth per capita falls back to subsistence.","tags":["economics","systems"]},
    {"front":"Bayesian","back":"Epistemic stance that beliefs are probabilistic and should be updated by Bayes' Rule.","tags":["rationalism","probability"]},
    {"front":"Two-income Trap","back":"As more households rely on two paychecks, bidding wars for fixed goods erase the extra income.","tags":["economics","systems"]},
    {"front":"Multipolar Trap","back":"Scenario where unilateral defection is rewarded and cooperation punished.","tags":["systems","game-theory"]},
    {"front":"Objectivism","back":"Ayn Rand's philosophy: objective reality, reason, rational self-interest, laissez-faire capitalism.","tags":["philosophy","economics"]},
    {"front":"Utilitarianism","back":"Moral theory: action is right if it maximizes aggregate well-being.","tags":["philosophy","ethics"]},
    {"front":"Orthogonality Thesis","back":"In AI theory: intelligence level is largely independent of final goals.","tags":["ai-safety","rationalism"]},
    {"front":"Goodhart's Law","back":"When a measure becomes a target, it ceases to be a good measure.","tags":["systems","measurement"]},
    {"front":"Chesterton's Fence","back":"Don't remove an old rule until you understand why it was built.","tags":["decision-making","systems"]},
    {"front":"Pascal's Mugging","back":"Low-probability, astronomically high-payoff scenarios that hijack expected-utility reasoning.","tags":["rationalism","decision"]},
    {"front":"Instrumental Convergence","back":"Diverse goals still imply similar sub-goals like resource acquisition and self-preservation.","tags":["ai-safety","rationalism"]},
    {"front":"Paperclip Maximizer","back":"Thought experiment: misaligned super-intelligence turns everything into paperclips.","tags":["ai-safety","rationalism"]},
    {"front":"Stock","back":"An accumulation at a point in time (water in a tank, money in a bank).","tags":["systems","thinking"]},
    {"front":"Flow","back":"Rate that adds to or subtracts from a stock (inflow, outflow).","tags":["systems","thinking"]},
    {"front":"Feedback Loop","back":"Circular causality where a change feeds back to influence itself.","tags":["systems","thinking"]},
    {"front":"Leverage Point","back":"Place in a system where a small shift yields big change.","tags":["systems","thinking"]},
    {"front":"Resilience","back":"System's capacity to absorb shock and still function.","tags":["systems","thinking"]},
    {"front":"Emergence","back":"Qualitatively new behavior appears at higher levels.","tags":["systems","philosophy"]}
  ]
}
